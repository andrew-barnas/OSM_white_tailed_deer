The purpose of this file is some data exploration on deers


```{r}
#Clear everything out and start fresh
rm(list=ls())
library(reproducible) #setting up directories for data management
library(readr)        #Needed to read and merge all the csv's in the camera folder
library(dplyr)        #data wranglin'
library(lubridate)    #datetime manipulation
library(tidyr)        #more data manipulation
library(stringr)      #detecting character strings
library(ggplot2)      #data visualization
library(purrr)        #feline-friendly loops 


#This just sets up files for inputs (already created, must contain your files), and outputs
input_directory<-reproducible::checkPath(file.path(getwd(), "inputs"), create = TRUE)
output_directory<-reproducible::checkPath(file.path(getwd(), "outputs"), create = TRUE)
figure_directory<-reproducible::checkPath(file.path(getwd(), "figures"), create = TRUE)


#read in the files we need
dets<-read.csv(file.path(input_directory, "OSM_camera_detections.csv"))
camop<-read.csv(file.path(input_directory, "OSM_camera_deployment.csv"))
covs<-read.csv(file.path(input_directory, "OSM_camera_covariates.csv"))

#And the weather data
weather<-read.csv(file.path(input_directory, "daymet_weather_data.csv"))

```

Lets first work on our response variable. This will be counts of independent detections in the months of may, june, july, and august each year. We will need a cutoff though to only use cameras that were operational for the full time slice each year.
```{r}

#First, filter the cameras to look only at those that had operation within the months of may, june, july, and august each year.
dets_summer<-dets%>%
  filter(month(datetime) %in% 5:8)%>%
  mutate(year = year(datetime))
  
dets_summer_operability <- dets %>%
  # keep only May–August
  filter(month(datetime) %in% 5:8) %>%
  #Add in a specific date and year column
   mutate(
    date = as_date(datetime),
    year = year(datetime)
  ) %>%
  group_by(site, year) %>%
  # count unique dates per site-year -> this will be the number of operating days!
  summarise(
    n_days = n_distinct(date),
    min_date = min(date),
    max_date = max(date),
    .groups = "drop"
  )

#Add a plot here for camera operability in the future

##Now lets work on independent detections of white tailed deer
#Note we did not filter to deer above, as we wanted to calculate full operability first!
wtd<-dets%>%
  filter(month(datetime) %in% 5:8)%>%
  filter(species == "White-tailed deer")%>%
  #Just ensuring its read in as a datetime here!
  mutate(datetime = ymd_hms(datetime))


#arrange the detection by site, species, and time, then group by site
wtd<-wtd%>%
  arrange(array, site, datetime)%>%
  group_by(site)%>%
  #Create a lag time that will be used to calculate time differences
   mutate(duration = as.numeric(difftime(datetime,lag(datetime),units = "mins")))


#Set up the framework for assigning unique IDs
wtd$Event.ID<-9999 #This is just an arbitrary event identification code
mins<-2 # THIS IS THE DETECTION EVENT BREAK-POINT YOU CAN CHANGE
seq <- as.numeric(paste0(nrow(wtd),0))
seq <- round(seq,-(nchar(seq)))

#This will go through each row and figure out how far apart in time each one is
#So this creates unique event identifications for subsequent rows IF they are more than 30mins apart
for (i in 2:nrow(wtd)) {
 wtd$Event.ID[i-1]  <- paste0("E",format(seq, scientific = F))
  if(is.na(wtd$duration[i]) | abs(wtd$duration[i]) > mins){
    seq <- seq + 1 
  }
}

# Update the information for the last row
# group ID  for the last row
if(wtd$duration[nrow(wtd)] < mins| 
   is.na(wtd$duration[nrow(wtd)])){
  wtd$Event.ID[nrow(wtd)] <- wtd$Event.ID[nrow(wtd)-1] 
} else{
  wtd$Event.ID[nrow(wtd)] <- paste0("E",format(seq+1, scientific = F)) 
}

# Subset to just top rows to get independent detections.

# Note: This is a critical step to make a decision on how we filter this - don't want to loose data by just taking first row when there are multiple rows of data in a detection? Just want to sum? take highest? THINK SYD

#Want to make sure at the end of this we still have the same number of independent detections!
wtd_ind_test<-wtd %>%
  group_by(Event.ID) %>% 
  filter(row_number()==1)%>%
  ungroup()

###############################################################
#Now lets figure out how many of these independent detections were those of lone adults vs adults with offspring
#I am going to make an assumption that detections of offspring without adults, actually were with adults. Since the chances of just having a random offspring running around without an adult is likely rare

#Lets reduce this down to the information we want
wtd<-wtd%>%
  dplyr::select(array, site, datetime, female, yoy, Event.ID)

#Second, since we don't care about absolute number of deer in events, we are going to turn things into binary present or absent. 

#First turn those NAs into zeros
wtd <- wtd %>%
  mutate(across(c(female, yoy),
                ~ ifelse(is.na(.x) | .x == 0, 0, 1)))

#Next, for event ID lets identify if a yoy was present or if a female was present
wtd<-wtd %>%
  group_by(Event.ID) %>%
  mutate(
    # Whether any yoy = 1 within the event
    yoy_present = as.integer(any(yoy == 1, na.rm = TRUE)),
    
    # Whether ONLY females were present (female = 1 somewhere, but no yoy = 1 anywhere)
    female_only = as.integer(any(female == 1, na.rm = TRUE) & !any(yoy == 1, na.rm = TRUE))
  ) %>%
  ungroup()

#Finally, lets reduce to one row per event, and filter out events with zeros for both categories (these would represent males and stuff)
wtd<-wtd%>%
  group_by(Event.ID)%>%
  filter(row_number()==1)%>%
  filter(!(yoy_present == 0 & female_only == 0))%>%
  ungroup()

#how many sites/years - this matches the next step so we are good
wtd%>%
  mutate(year = year(datetime))%>%
  group_by(year)%>%
  summarise(n_sites = n_distinct(site))

#And now lets calculate the number of events per site per year
wtd<-wtd%>%
  mutate(year = year(datetime))%>%
  group_by(year, site)%>%
  summarise(n_yoy = sum(yoy_present),
            n_female = sum(female_only))%>%
  arrange(site)

#Ok now remember one thing that will be missing here is sites that had zero and zero. We can get this list from the dets_summer_operability. This represents the number of sites per year that were operated
dets_summer_operability%>%
  group_by(year)%>%
  summarise(n_obs = n_distinct(site))

#And this represents the number of sites per year that had a deer deteciton we care about.
#see how its much lower, we need to add in the true zeros from the cameras we know were on but did not detect deer 
wtd%>%
  group_by(year)%>%
  summarise(n_obs = n_distinct(site))

#This will merge the dataframes, and leave NAs for the cameras where no deer were detected. We will simply then replace the NAs with zeros
wtd<-merge(dets_summer_operability,
wtd, all.x = TRUE)%>%
  mutate(n_yoy = ifelse(is.na(n_yoy), 0, n_yoy),
         n_female = ifelse(is.na(n_female), 0, n_female))

#And finally, lets add coordinates for each site in
wtd<-merge(wtd, 
      camop%>%
      dplyr::select(array, site, lat, long),
      by = c("site"), all.x = TRUE)

#And last, lets compute an "index" of detections by accounting for camera trap days
wtd<-wtd%>%
  mutate(yoy_index = n_yoy/n_days,
         female_index = n_female/n_days)

#Some baby data exploration
ggplot(wtd, aes(x = female_index))+
  geom_histogram(fill = "grey", color = "black")+
  xlab("Adult female detections per camera day")

ggplot(wtd, aes(x = yoy_index))+
  geom_histogram(fill = "grey", color = "black")+
  xlab("YOY detections per camera day")




```



Adding in landscape disturbance
```{r}

#temporary for messing around
df<-wtd


#Ok lets work on the covariates. I am just going to make a broad disturbance index for each site
#at 1000m reflecting the camera spacing
covs<-covs%>%
  filter(buff_dist == 1000)%>%
  #remove the habitat classifications
  dplyr::select(-c(lc_class110, lc_class120, lc_class20, lc_class210, lc_class220, lc_class230, lc_class32, lc_class33, lc_class34, lc_class50))

#Create a sum across columns 4 to 50
covs<-covs%>%
  mutate(disturbance_index = rowSums(across(4:50)))%>%
  dplyr::select(array, site, disturbance_index)

ggplot(covs, aes(x = disturbance_index))+
  geom_histogram()+
  facet_wrap(~array)

#Lets link that into the detection file
df<-merge(df, covs, by = c("site", "array"))

#quick and dirty data exploration
ggplot(df, aes(x = disturbance_index, y = female_index, color = array))+
  geom_point(size = 3)+
  ylab("Female detection index")+
  xlab("Disturbance index")+
  ggtitle("Females ~ disturbance")

ggplot(df, aes(x = disturbance_index, y = yoy_index, color = array))+
  geom_point(size = 3)+
  ylab("YOY detection index")+
  xlab("Disturbance index")+
  ggtitle("YOY~ disturbance")


```


Climate data
```{r}
#dataframe of deer detections and disturbance index
df

#weather stuff
weather


#So first things first, lets keep life simple and just look at temperature and snow
weather<-weather%>%
  dplyr::select(c(site, latitude, longitude, year, day, max_temp_C, snow_water_equiv_kgM2))


#And I am pretty sure we will need to get those dates read in nicely
weather <- weather %>%
  mutate(date = ymd(paste0(year, "-01-01")) + days(day - 1))

#Interesting. quick plot?
weather%>%
  group_by(date)%>%
  summarise(mean_snow = mean(snow_water_equiv_kgM2),
            sd_snow = sd(snow_water_equiv_kgM2))%>%
  ggplot(aes(x = date))+
  geom_ribbon(aes(ymin = mean_snow - sd_snow, ymax = mean_snow + sd_snow), fill = "grey70") +
  geom_line(aes(y = mean_snow))+
  ggtitle("snow water equivalent")


#Ok lets pick an arbitrary winter period. Lets say october to february?
#First just keep data in those months
weather<-weather%>%
  filter(month(date) %in% c(10, 11, 12, 1, 2))
  

#Ok ok. Now remember, the weather dataframe has data for all sites for all years. But we don't need that 
weather_summary <- weather %>%
  # Extract month for filtering
  mutate(month = month(date),
         # Define "winter_year" = the year that the winter *starts*
         winter_year = if_else(month >= 10, year(date), year(date) - 1)) %>%
  
  # Keep only October through February
  filter(month %in% c(10, 11, 12, 1, 2)) %>%
  
  # Group by site and winter season
  group_by(site, winter_year) %>%
  
  # Summarize mean and sd for each variable
  summarise(
    mean_temp = mean(max_temp_C, na.rm = TRUE),
    sd_temp   = sd(max_temp_C, na.rm = TRUE),
    mean_swe  = mean(snow_water_equiv_kgM2, na.rm = TRUE),
    sd_swe    = sd(snow_water_equiv_kgM2, na.rm = TRUE),
    n_days    = n(),  # optional — good to check how many days were available
    .groups = "drop"
  )

#Filter and check the summaries
weather_summary<-weather_summary%>%
  filter(!winter_year %in% c(2019, 2024))

#I need to understand this, why some are 150 days, some are 151, and other 152...
#IGNORING FOR NOW
ggplot(weather_summary, aes(x = n_days))+
  geom_histogram()


#Ok now we need to add the right winter year in for each detection thing
#So if the year in the detection is 2021, we want winter year 2020
df_joined <- df %>%
  mutate(winter_year = year - 1) %>%   # winter before the summer field season
  left_join(
    weather_summary %>%
      rename_with(~ paste0("winter_", .), c(mean_temp, sd_temp, mean_swe, sd_swe, n_days)),
    by = c("site" = "site", "winter_year" = "winter_year")
  )

#Quick and dirty plots?
ggplot(df_joined, aes(x = winter_mean_temp, y = female_index, color = array))+
  geom_point(size = 3)+
  ylab("Female detection index")+
  xlab("winter_temp")+
  ggtitle("Females ~ winter temp")

ggplot(df_joined, aes(x = winter_mean_temp, y = yoy_index, color = array))+
  geom_point(size = 3)+
  ylab("YOY detection index")+
  xlab("winter_temp")+
  ggtitle("yoy ~ winter temp")



ggplot(df_joined, aes(x = winter_mean_swe, y = female_index, color = array))+
  geom_point(size = 3)+
  ylab("Female detection index")+
  xlab("snow")+
  ggtitle("Females ~ snow")

ggplot(df_joined, aes(x = winter_mean_swe, y = yoy_index, color = array))+
  geom_point(size = 3)+
  ylab("YOY detection index")+
  xlab("snow")+
  ggtitle("yoy ~ snow")

```


Cheeky first pass models
```{r}

#scale variables of interest
df_joined<-df_joined%>%
  mutate(scale_max_temp = scale(winter_mean_temp),
         scale_snow = scale(winter_mean_swe),
         scale_disturbance = scale(disturbance_index))
hist(df_joined$scale_max_temp)
hist(df_joined$scale_snow)
hist(df_joined$scale_disturbance)


#Quick global model for adults
m1<-glmmTMB::glmmTMB(n_female ~ scale_disturbance + scale_snow + scale_disturbance*scale_snow+
                   (1|array) + (1|year)+
                  offset(log(n_days)),
                 family = poisson(),
                 data = df_joined)
summary(m1)

m2<-glmmTMB::glmmTMB(n_yoy ~ scale_disturbance + scale_snow + scale_disturbance*scale_snow+
                   (1|array) + (1|year)+
                  offset(log(n_days)),
                 family = poisson(),
                 data = df_joined)
summary(m2)

lowQ  <- quantile(df_joined$scale_disturbance, 0.25, na.rm = TRUE)
highQ <- quantile(df_joined$scale_disturbance, 0.75, na.rm = TRUE)

# Generate predictions across the range of snow, at low and high disturbance
pred_m2 <- ggpredict(
  m2,
  terms = c("scale_snow", 
            paste0("scale_disturbance [", round(lowQ, 2), ",", round(highQ, 2), "]")),
   condition = c(n_days = 1) #represent a single camera day
)

# Plot
ggplot(pred_m2, aes(x = x, y = predicted, colour = group)) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, colour = NA) +
  labs(
    x = "Scaled snow",
    y = "Predicted number of YOY detections (per camera-day)",
    colour = "Disturbance (quartile)",
    fill = "Disturbance (quartile)"
  ) +
  theme_minimal(base_size = 14)

```
