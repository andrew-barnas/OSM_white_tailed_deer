The purpose of this file is some data exploration on deers


```{r}
#Clear everything out and start fresh
rm(list=ls())
library(reproducible) #setting up directories for data management
library(readr)        #Needed to read and merge all the csv's in the camera folder
library(dplyr)        #data wranglin'
library(lubridate)    #datetime manipulation
library(tidyr)        #more data manipulation
library(stringr)      #detecting character strings
library(ggplot2)      #data visualization
library(purrr)        #feline-friendly loops 


#This just sets up files for inputs (already created, must contain your files), and outputs
input_directory<-reproducible::checkPath(file.path(getwd(), "inputs"), create = TRUE)
output_directory<-reproducible::checkPath(file.path(getwd(), "outputs"), create = TRUE)
figure_directory<-reproducible::checkPath(file.path(getwd(), "figures"), create = TRUE)


#read in the files we need
dets<-read.csv(file.path(input_directory, "OSM_camera_detections.csv"))
camop<-read.csv(file.path(input_directory, "OSM_camera_deployment.csv"))
covs<-read.csv(file.path(input_directory, "OSM_camera_covariates.csv"))

#And the weather data
weather<-read.csv(file.path(input_directory, "daymet_weather_data.csv"))

```

I want a plot of detections for each of the following groups over the course of the year: adults, juveniles, you
```{r}
wtd<-dets%>%
  filter(species == "White-tailed deer")%>%
  #Just ensuring its read in as a datetime here!
  mutate(datetime = ymd_hms(datetime))

#arrange the detection by site, species, and time, then group by site
wtd<-wtd%>%
  arrange(array, site, datetime)%>%
  group_by(site)%>%
  #Create a lag time that will be used to calculate time differences
   mutate(duration = as.numeric(difftime(datetime,lag(datetime),units = "mins")))


#Set up the framework for assigning unique IDs
wtd$Event.ID<-9999 #This is just an arbitrary event identification code
mins<-2 # THIS IS THE DETECTION EVENT BREAK-POINT YOU CAN CHANGE
seq <- as.numeric(paste0(nrow(wtd),0))
seq <- round(seq,-(nchar(seq)))

#This will go through each row and figure out how far apart in time each one is
#So this creates unique event identifications for subsequent rows IF they are more than 30mins apart
for (i in 2:nrow(wtd)) {
 wtd$Event.ID[i-1]  <- paste0("E",format(seq, scientific = F))
  if(is.na(wtd$duration[i]) | abs(wtd$duration[i]) > mins){
    seq <- seq + 1 
  }
}

# Update the information for the last row
# group ID  for the last row
if(wtd$duration[nrow(wtd)] < mins| 
   is.na(wtd$duration[nrow(wtd)])){
  wtd$Event.ID[nrow(wtd)] <- wtd$Event.ID[nrow(wtd)-1] 
} else{
  wtd$Event.ID[nrow(wtd)] <- paste0("E",format(seq+1, scientific = F)) 
}


#Want to make sure at the end of this we still have the same number of independent detections!
wtd_ind_test<-wtd %>%
  group_by(Event.ID) %>% 
  filter(row_number()==1)%>%
  ungroup()

###############################################################
#Now lets figure out how many of these independent detections were those of lone adults vs adults with offspring
#I am going to make an assumption that detections of offspring without adults, actually were with adults. Since the chances of just having a random offspring running around without an adult is likely rare

#Lets reduce this down to the information we want
wtd<-wtd%>%
  dplyr::select(array, site, datetime, female, yly, yoy, Event.ID)

#Second, since we don't care about absolute number of deer in events, we are going to turn things into binary present or absent. 

#First turn those NAs into zeros
wtd <- wtd %>%
  mutate(across(c(female, yly, yoy),
                ~ ifelse(is.na(.x) | .x == 0, 0, 1)))

#Next, for event ID lets identify if a yoy was present or if a female was present
wtd<-wtd %>%
  group_by(Event.ID) %>%
  mutate(
    # Whether any yoy = 1 within the event
    yoy_present = as.integer(any(yoy == 1, na.rm = TRUE)),
    
    #Whether juvenile present
    yly_present = as.integer(any(yly == 1, na.rm = TRUE)),
    
    # Whether ONLY females were present (female = 1 somewhere, but no yoy = 1 anywhere)
    female_only = as.integer(any(female == 1, na.rm = TRUE) & !any(yoy == 1, na.rm = TRUE) & !any(yly == 1, na.rm = TRUE))
  ) %>%
  ungroup()

#Finally, lets reduce to one row per event, and filter out events with zeros for both categories (these would represent males and stuff)
wtd<-wtd%>%
  group_by(Event.ID)%>%
  filter(row_number()==1)%>%
  filter(!(yoy_present == 0 & yly_present == 0 & female_only == 0))%>%
  ungroup()

#Ok give me a graph for each one of detections across the year
wtd_summary<-wtd%>%
  mutate(month = month(datetime, label = TRUE, abbr = TRUE)) %>%  # extract month name
  group_by(array, month) %>%
  summarise(
    yoy_present = sum(yoy_present, na.rm = TRUE),
    yly_present = sum(yly_present, na.rm = TRUE),
    female_only = sum(female_only, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(yoy_present, yly_present, female_only),
    names_to = "group",
    values_to = "count"
  )


ggplot(wtd_summary, aes(x = month, y = count, fill = array)) +
  geom_col(position = "dodge") +
  facet_wrap(~ group, nrow = 3) +
  theme_minimal() +
  labs(
    x = "Month",
    y = "Sum of detections",
    fill = "Camera Array"
  )

#how many sites/years - this matches the next step so we are good
wtd%>%
  mutate(year = year(datetime))%>%
  group_by(year)%>%
  summarise(n_sites = n_distinct(site))

#And now lets calculate the number of events per site per year
wtd<-wtd%>%
  mutate(year = year(datetime))%>%
  group_by(year, site)%>%
  summarise(n_yoy = sum(yoy_present),
            n_female = sum(female_only))%>%
  arrange(site)

#Ok now remember one thing that will be missing here is sites that had zero and zero. We can get this list from the dets_summer_operability. This represents the number of sites per year that were operated
dets_summer_operability%>%
  group_by(year)%>%
  summarise(n_obs = n_distinct(site))

#And this represents the number of sites per year that had a deer deteciton we care about.
#see how its much lower, we need to add in the true zeros from the cameras we know were on but did not detect deer 
wtd%>%
  group_by(year)%>%
  summarise(n_obs = n_distinct(site))

#This will merge the dataframes, and leave NAs for the cameras where no deer were detected. We will simply then replace the NAs with zeros
wtd<-merge(dets_summer_operability,
wtd, all.x = TRUE)%>%
  mutate(n_yoy = ifelse(is.na(n_yoy), 0, n_yoy),
         n_female = ifelse(is.na(n_female), 0, n_female))

#And finally, lets add coordinates for each site in
wtd<-merge(wtd, 
      camop%>%
      dplyr::select(array, site, lat, long),
      by = c("site"), all.x = TRUE)

#And last, lets compute an "index" of detections by accounting for camera trap days
wtd<-wtd%>%
  mutate(yoy_index = n_yoy/n_days,
         female_index = n_female/n_days)

#Some baby data exploration
ggplot(wtd, aes(x = female_index))+
  geom_histogram(fill = "grey", color = "black")+
  xlab("Adult female detections per camera day")

ggplot(wtd, aes(x = yoy_index))+
  geom_histogram(fill = "grey", color = "black")+
  xlab("YOY detections per camera day")





```


First 
```{r}

#First, filter the cameras to look only at those that had operation within the months of may, june, july, and august each year.

  
dets_summer_operability <- dets %>%
  # keep only May–August
  filter(month(datetime) %in% 5:8) %>%
  #Add in a specific date and year column
   mutate(
    date = as_date(datetime),
    year = year(datetime)
  ) %>%
  group_by(site, year) %>%
  # count unique dates per site-year -> this will be the number of operating days!
  summarise(
    n_days = n_distinct(date),
    min_date = min(date),
    max_date = max(date),
    .groups = "drop"
  )

#Add a plot here for camera operability in the future

##Now lets work on independent detections of white tailed deer
#Note we did not filter to deer above, as we wanted to calculate full operability first!
wtd<-dets%>%
  filter(month(datetime) %in% 5:8)%>%
  filter(species == "White-tailed deer")%>%
  #Just ensuring its read in as a datetime here!
  mutate(datetime = ymd_hms(datetime))


#arrange the detection by site, species, and time, then group by site
wtd<-wtd%>%
  arrange(array, site, datetime)%>%
  group_by(site)%>%
  #Create a lag time that will be used to calculate time differences
   mutate(duration = as.numeric(difftime(datetime,lag(datetime),units = "mins")))


#Set up the framework for assigning unique IDs
wtd$Event.ID<-9999 #This is just an arbitrary event identification code
mins<-2 # THIS IS THE DETECTION EVENT BREAK-POINT YOU CAN CHANGE
seq <- as.numeric(paste0(nrow(wtd),0))
seq <- round(seq,-(nchar(seq)))

#This will go through each row and figure out how far apart in time each one is
#So this creates unique event identifications for subsequent rows IF they are more than 30mins apart
for (i in 2:nrow(wtd)) {
 wtd$Event.ID[i-1]  <- paste0("E",format(seq, scientific = F))
  if(is.na(wtd$duration[i]) | abs(wtd$duration[i]) > mins){
    seq <- seq + 1 
  }
}

# Update the information for the last row
# group ID  for the last row
if(wtd$duration[nrow(wtd)] < mins| 
   is.na(wtd$duration[nrow(wtd)])){
  wtd$Event.ID[nrow(wtd)] <- wtd$Event.ID[nrow(wtd)-1] 
} else{
  wtd$Event.ID[nrow(wtd)] <- paste0("E",format(seq+1, scientific = F)) 
}

# Subset to just top rows to get independent detections.

# Note: This is a critical step to make a decision on how we filter this - don't want to loose data by just taking first row when there are multiple rows of data in a detection? Just want to sum? take highest? THINK SYD

#Want to make sure at the end of this we still have the same number of independent detections!
wtd_ind_test<-wtd %>%
  group_by(Event.ID) %>% 
  filter(row_number()==1)%>%
  ungroup()

###############################################################
#Now lets figure out how many of these independent detections were those of lone adults vs adults with offspring
#I am going to make an assumption that detections of offspring without adults, actually were with adults. Since the chances of just having a random offspring running around without an adult is likely rare

#Lets reduce this down to the information we want
wtd<-wtd%>%
  dplyr::select(array, site, datetime, female, yoy, Event.ID)

#Second, since we don't care about absolute number of deer in events, we are going to turn things into binary present or absent. 

#First turn those NAs into zeros
wtd <- wtd %>%
  mutate(across(c(female, yoy),
                ~ ifelse(is.na(.x) | .x == 0, 0, 1)))

#Next, for event ID lets identify if a yoy was present or if a female was present
wtd<-wtd %>%
  group_by(Event.ID) %>%
  mutate(
    # Whether any yoy = 1 within the event
    yoy_present = as.integer(any(yoy == 1, na.rm = TRUE)),
    
    # Whether ONLY females were present (female = 1 somewhere, but no yoy = 1 anywhere)
    female_only = as.integer(any(female == 1, na.rm = TRUE) & !any(yoy == 1, na.rm = TRUE))
  ) %>%
  ungroup()

#Finally, lets reduce to one row per event, and filter out events with zeros for both categories (these would represent males and stuff)
wtd<-wtd%>%
  group_by(Event.ID)%>%
  filter(row_number()==1)%>%
  filter(!(yoy_present == 0 & female_only == 0))%>%
  ungroup()

#how many sites/years - this matches the next step so we are good
wtd%>%
  mutate(year = year(datetime))%>%
  group_by(year)%>%
  summarise(n_sites = n_distinct(site))

#And now lets calculate the number of events per site per year
wtd<-wtd%>%
  mutate(year = year(datetime))%>%
  group_by(year, site)%>%
  summarise(n_yoy = sum(yoy_present),
            n_female = sum(female_only))%>%
  arrange(site)

#Ok now remember one thing that will be missing here is sites that had zero and zero. We can get this list from the dets_summer_operability. This represents the number of sites per year that were operated
dets_summer_operability%>%
  group_by(year)%>%
  summarise(n_obs = n_distinct(site))

#And this represents the number of sites per year that had a deer deteciton we care about.
#see how its much lower, we need to add in the true zeros from the cameras we know were on but did not detect deer 
wtd%>%
  group_by(year)%>%
  summarise(n_obs = n_distinct(site))

#This will merge the dataframes, and leave NAs for the cameras where no deer were detected. We will simply then replace the NAs with zeros
wtd<-merge(dets_summer_operability,
wtd, all.x = TRUE)%>%
  mutate(n_yoy = ifelse(is.na(n_yoy), 0, n_yoy),
         n_female = ifelse(is.na(n_female), 0, n_female))

#And finally, lets add coordinates for each site in
wtd<-merge(wtd, 
      camop%>%
      dplyr::select(array, site, lat, long),
      by = c("site"), all.x = TRUE)

#And last, lets compute an "index" of detections by accounting for camera trap days
wtd<-wtd%>%
  mutate(yoy_index = n_yoy/n_days,
         female_index = n_female/n_days)

#Some baby data exploration
ggplot(wtd, aes(x = female_index))+
  geom_histogram(fill = "grey", color = "black")+
  xlab("Adult female detections per camera day")

ggplot(wtd, aes(x = yoy_index))+
  geom_histogram(fill = "grey", color = "black")+
  xlab("YOY detections per camera day")




```



Adding in landscape disturbance
```{r}
#I need to go through the covariate list and classify them either as polygonal or linear or unknown
covs<-covs%>%
  mutate(polygonal_sum = borrowpits + clearing_wellpad_unconfirmed + crop + facility_other + golfcourse + harvest_area + lagoon + mines_oilsands + oil_gas_plant + residence_clearing + ris_camp_industrial + ris_facility_operations + well_bitumen + well_cleared_not_drilled + well_other + borrowpit_dry + camp_industrial + cultivation_abandoned + facility_unknown + harvest_area_white_zone + landfill + mines_pitlake + open_pit_mine + ris_clearing_unknown + ris_overburden_dump + ris_tailing_pond + rural_residence + tailing_pond + transfer_station + urban_industrial + well_cased + well_gas + well_unknown + borrowpit_wet + campground + clearing_unknown + country_residence + dugout + grvl_sand_pit + mill + misc_oil_gas_facility + reservoir + ris_borrowpits + ris_mines_oilsands + ris_plant + rough_pasture + tame_pasture + urban_residence + well_aband + well_cleared_not_confirmed + well_oil,
         
         linear_sum = pipeline + ris_transmission_line + rlwy_sgl_track + road_gravel_1l + road_gravel_2l + road_paved_1l + road_paved_2l + road_paved_3l + road_paved_4l + road_paved_5l + road_paved_div + road_paved_undiv_1l + road_paved_undiv_2l + runway + trail + truck_trail + vegetated_edge_railways  + conventional_seismic + low_impact_seismic + ris_airp_runway + ris_road + rlwy_dbl_track + rlwy_spur + vegetated_edge_roads + rlwy_mlt_track + transmission_line)
         



#temporary for messing around
df<-wtd


#Ok lets work on the covariates. I am just going to make a broad disturbance index for each site
#at 1000m reflecting the camera spacing
covs<-covs%>%
  filter(buff_dist == 1000)%>%
  #Lets hang on to a couple of these habitat variables
  rename(grassland = lc_class110,
         broadleaf = lc_class220)%>%
  #remove the habitat classifications
  dplyr::select(-c(lc_class120, lc_class20, lc_class210, lc_class230, lc_class32, lc_class33, lc_class34, lc_class50))

#Create a sum across columns 4 to 50
covs<-covs%>%
  dplyr::select(array, site, grassland, broadleaf, polygonal_sum, linear_sum)



#Lets link that into the detection file
df<-merge(df, covs, by = c("site", "array"))

#quick and dirty data exploration
# ggplot(df, aes(x = disturbance_index, y = female_index, color = array))+
#   geom_point(size = 3)+
#   ylab("Female detection index")+
#   xlab("Disturbance index")+
#   ggtitle("Females ~ disturbance")
# 
# ggplot(df, aes(x = disturbance_index, y = yoy_index, color = array))+
#   geom_point(size = 3)+
#   ylab("YOY detection index")+
#   xlab("Disturbance index")+
#   ggtitle("YOY~ disturbance")


```


Climate data
```{r}
#dataframe of deer detections and disturbance index
df

#weather stuff
weather


#So first things first, lets keep life simple and just look at temperature and snow
weather<-weather%>%
  dplyr::select(c(site, latitude, longitude, year, day, max_temp_C, snow_water_equiv_kgM2))


#And I am pretty sure we will need to get those dates read in nicely
weather <- weather %>%
  mutate(date = ymd(paste0(year, "-01-01")) + days(day - 1))

#Interesting. quick plot?
weather%>%
  group_by(date)%>%
  summarise(mean_snow = mean(snow_water_equiv_kgM2),
            sd_snow = sd(snow_water_equiv_kgM2))%>%
  ggplot(aes(x = date))+
  geom_ribbon(aes(ymin = mean_snow - sd_snow, ymax = mean_snow + sd_snow), fill = "grey70") +
  geom_line(aes(y = mean_snow))+
  ggtitle("snow water equivalent")


#Ok lets pick an arbitrary winter period. Lets say october to february?
#First just keep data in those months
weather<-weather%>%
  filter(month(date) %in% c(10, 11, 12, 1, 2))
  

#Ok ok. Now remember, the weather dataframe has data for all sites for all years. But we don't need that 
weather_summary <- weather %>%
  # Extract month for filtering
  mutate(month = month(date),
         # Define "winter_year" = the year that the winter *starts*
         winter_year = if_else(month >= 10, year(date), year(date) - 1)) %>%
  
  # Keep only October through February
  filter(month %in% c(10, 11, 12, 1, 2)) %>%
  
  # Group by site and winter season
  group_by(site, winter_year) %>%
  
  # Summarize mean and sd for each variable
  summarise(
    mean_temp = mean(max_temp_C, na.rm = TRUE),
    sd_temp   = sd(max_temp_C, na.rm = TRUE),
    mean_swe  = mean(snow_water_equiv_kgM2, na.rm = TRUE),
    sd_swe    = sd(snow_water_equiv_kgM2, na.rm = TRUE),
    n_days    = n(),  # optional — good to check how many days were available
    .groups = "drop"
  )

#Filter and check the summaries
weather_summary<-weather_summary%>%
  filter(!winter_year %in% c(2019, 2024))

#I need to understand this, why some are 150 days, some are 151, and other 152...
#IGNORING FOR NOW
ggplot(weather_summary, aes(x = n_days))+
  geom_histogram()


#Ok now we need to add the right winter year in for each detection thing
#So if the year in the detection is 2021, we want winter year 2020
df_joined <- df %>%
  mutate(winter_year = year - 1) %>%   # winter before the summer field season
  left_join(
    weather_summary %>%
      rename_with(~ paste0("winter_", .), c(mean_temp, sd_temp, mean_swe, sd_swe, n_days)),
    by = c("site" = "site", "winter_year" = "winter_year")
  )

#Quick and dirty plots?
ggplot(df_joined, aes(x = winter_mean_temp, y = female_index, color = array))+
  geom_point(size = 3)+
  ylab("Female detection index")+
  xlab("winter_temp")+
  ggtitle("Females ~ winter temp")

ggplot(df_joined, aes(x = winter_mean_temp, y = yoy_index, color = array))+
  geom_point(size = 3)+
  ylab("YOY detection index")+
  xlab("winter_temp")+
  ggtitle("yoy ~ winter temp")



ggplot(df_joined, aes(x = winter_mean_swe, y = female_index, color = array))+
  geom_point(size = 3)+
  ylab("Female detection index")+
  xlab("snow")+
  ggtitle("Females ~ snow")

ggplot(df_joined, aes(x = winter_mean_swe, y = yoy_index, color = array))+
  geom_point(size = 3)+
  ylab("YOY detection index")+
  xlab("snow")+
  ggtitle("yoy ~ snow")

```


Cheeky first pass models
```{r}
#just throwing shit at the wall here
m1<-glmmTMB::glmmTMB(n_female ~ wells*winter_mean_swe+
                   (1|array) + (1|year)+
                  offset(log(n_days)),
                 family = poisson(),
                 data = df_joined)
summary(m1)





#scale variables of interest
df_joined<-df_joined%>%
  mutate(scale_max_temp = scale(winter_mean_temp),
         scale_snow = scale(winter_mean_swe),
         scale_polygonal = scale(polygonal_sum),
         scale_broadleaf = scale(broadleaf),
         scale_linear = scale(linear_sum))

hist(df_joined$scale_polygonal)
hist(df_joined$scale_linear)
hist(df_joined$scale_broadleaf)
hist(df_joined$scale_snow)

#correlation tests?
# Select your variables
vars <- df_joined %>%
  dplyr::select(scale_max_temp, scale_snow, scale_polygonal, scale_linear, scale_broadleaf)

# Compute correlation matrix (use complete.obs to ignore NAs)
cor_matrix <- cor(vars, use = "complete.obs")

# Print the correlation matrix
print(round(cor_matrix, 2))

# Visualize it
corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, addCoef.col = "black")


#Quick global model for adults
m1<-glmmTMB::glmmTMB(n_female ~ scale_snow + scale_linear + scale_polygonal + scale_broadleaf +
                   (1|array) + (1|year)+
                  offset(log(n_days)),
                 family = poisson(),
                 data = df_joined)
summary(m1)


m2<-glmmTMB::glmmTMB(n_female ~ scale_snow + scale_linear + scale_polygonal + scale_broadleaf + scale_snow*scale_polygonal+
                   (1|array) + (1|year)+
                  offset(log(n_days)),
                 family = poisson(),
                 data = df_joined)
summary(m2)


m3<-glmmTMB::glmmTMB(n_yoy ~ scale_snow + scale_linear + scale_polygonal + scale_broadleaf + scale_snow*scale_polygonal+
                   (1|array) + (1|year)+
                  offset(log(n_days)),
                 family = poisson(),
                 data = df_joined)
summary(m3)



lowQ  <- quantile(df_joined$scale_polygonal, 0.25, na.rm = TRUE)
highQ <- quantile(df_joined$scale_polygonal, 0.75, na.rm = TRUE)

# Generate predictions across the range of snow, at low and high disturbance
pred_m3 <- ggpredict(
  m3,
  terms = c("scale_snow", 
            paste0("scale_polygonal [", round(lowQ, 2), ",", round(highQ, 2), "]")),
   condition = c(n_days = 1) #represent a single camera day
)

# Plot
ggplot(pred_m3, aes(x = x, y = predicted, colour = group)) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, colour = NA) +
  labs(
    x = "Scaled snow",
    y = "Predicted number of YOY detections (per camera-day)",
    colour = "Disturbance (quartile)",
    fill = "Disturbance (quartile)"
  ) +
  theme_minimal(base_size = 14)

```
